#!/usr/bin/env python

import argparse
import os
import sys
import subprocess
import re
import json
import git
import logging
import hashlib
from collections import defaultdict, OrderedDict

from git_theta import git_utils, checkpoints, params, file_io, utils

logging.basicConfig(
    level=logging.DEBUG,
    format="git-theta-filter: [%(asctime)s] %(levelname)s - %(message)s",
)


def parse_args():
    parser = argparse.ArgumentParser(description="git-theta filter program")
    subparsers = parser.add_subparsers(title="Commands", dest="command")
    subparsers.required = True

    clean_parser = subparsers.add_parser("clean", help="clean filter")
    clean_parser.add_argument("file", help="file being passed to clean filter")
    clean_parser.set_defaults(func=clean)

    smudge_parser = subparsers.add_parser("smudge", help="smudge filter")
    smudge_parser.add_argument("file", help="file being passed to smudge filter")
    smudge_parser.set_defaults(func=smudge)

    args = parser.parse_args()
    return args


def clean(args):
    """
    Implements clean filter for model files
    Metadata file looks as follows:
    {
    "model/scoping/to/param/1-weight": {
        "tensor_metadata": {
            "shape": List[str],
            "dtype": str,
            "hash": str,
        },
    },
    ...,
    "model/scoping/to/param/2-bias": {
        "tensor_metadata": {
            "shape": List[str],
            "dtype": str,
            "hash": str,
        },
    },
    ...,
    }
    """
    logging.debug(f"Running clean filter on {args.file}")

    repo = git_utils.get_git_repo()
    model_path = git_utils.get_relative_path_from_root(repo, args.file)
    theta_model_dir = git_utils.get_relative_path_from_root(repo, git_utils.get_git_theta_model_dir(repo, model_path))

    # TODO(bdlester): Find a better way to include checkpoint type information
    # in git clean filters that are run without `git theta add`.
    # TODO: Don't default to pytorch once other checkpoint formats are supported.
    checkpoint_type = os.environ.get("GIT_THETA_CHECKPOINT_TYPE") or "pytorch"
    checkpoint = checkpoints.get_checkpoint(checkpoint_type)
    model_checkpoint = checkpoint.from_file(sys.stdin.buffer)
    # TODO(bdlester): If we use Python3.7 as the minimum version, we don't need
    # to use an OrderedDict as the standard dict retains the insertion order.
    staged_file_contents = OrderedDict({"model_dir": theta_model_dir})
    # Sort the keys so we don't get changing diffs based on serialization order.
    for keys, param in sorted(utils.flatten(model_checkpoint).items()):
        param_name = "/".join(keys)
        tensor_metadata = OrderedDict({"shape": params.get_shape_str(param), "dtype": params.get_dtype_str(param), "hash": params.get_hash(param)})
        staged_file_contents[param_name] = OrderedDict({"tensor_metadata": tensor_metadata}) 

    file_io.write_staged_file(sys.stdout, staged_file_contents)


def smudge(args):
    """
    Implements smudge filter for model files
    """
    logging.debug(f"Running smudge filter on {args.file}")

    repo = git_utils.get_git_repo()
    staged_file = file_io.load_staged_file(sys.stdin)

    model_dict = {}
    for keys, param_dir in utils.flatten(utils.walk_parameter_dir(
        os.path.abspath(staged_file["model_dir"])
    )).items():
        param_file = os.path.join(param_dir, "params")
        logging.debug(f"Populating model parameter {'/'.join(keys)}")
        model_dict[keys] = file_io.load_tracked_file(param_file)

    model_dict = utils.unflatten(model_dict)
    model_checkpoint = checkpoints.PyTorchCheckpoint(model_dict)
    model_checkpoint.save(sys.stdout.buffer)


if __name__ == "__main__":
    args = parse_args()
    args.func(args)
